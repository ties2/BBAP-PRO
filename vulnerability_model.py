import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
import pickle

# Sample dataset (you can expand this with real vulnerability data)
data = {
    'description': [
        'user input not sanitized before executing SQL query',
        'javascript code inserted into user input',
        'remote code execution possible due to buffer overflow',
        'cross-site scripting in user form',
        'command injection vulnerability',
        'open redirect flaw'
    ],
    'category': [
        'SQL Injection', 'XSS', 'Remote Code Execution', 'XSS', 'Command Injection', 'Open Redirect'
    ]
}

# Create a dataframe
df = pd.DataFrame(data)

# Features and labels
X = df['description']
y = df['category']

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Machine learning pipeline
# Step 2: Create machine learning pipeline
# Next, we'll create a pipeline consisting of TF-IDF vectorization and logistic regression classification.
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer()),  # Convert text to numerical features
    ('classifier', LogisticRegression())  # Use Logistic Regression as the classifier
])

# Train the model
# we'll train the model on the training data.
pipeline.fit(X_train, y_train)


# Create models directory if it doesn't exist
os.makedirs('models', exist_ok=True)

# Save the trained model
# save the trained model using pickle for future use.
with open('models/vulnerability_classifier.pkl', 'wb') as model_file:
    pickle.dump(pipeline, model_file)

# Evaluate the model
# we'll evaluate the model's performance on the test set.
accuracy = pipeline.score(X_test, y_test)
print(f'Model accuracy: {accuracy * 100:.2f}%')