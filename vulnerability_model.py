# main.py
import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
import pickle

# Load the dataset from the CSV file
df = pd.read_csv('advanced_vulnerability_dataset.csv')

# Features and labels
X = df['description']
y = df['category']

# Check how many classes you have
print("Class distribution in the dataset:")
print(y.value_counts())

# Verify that every class has at least two samples before splitting
class_counts = y.value_counts()


# Remove classes with less than 2 samples
classes_to_remove = class_counts[class_counts < 2].index
if len(classes_to_remove) > 0:
    print(f"Removing the following classes with less than 2 samples: {classes_to_remove}")
    df = df[~df['category'].isin(classes_to_remove)]
    X = df['description']
    y = df['category']

# Split the data into train and test sets (with stratify to maintain proportion of classes)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=6, random_state=42, stratify=y)

# Print class distribution in train and test sets
print("\nClass distribution in the training set:")
print(y_train.value_counts())

print("\nClass distribution in the test set:")
print(y_test.value_counts())

# Machine learning pipeline
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer()),  # Convert text to numerical features
    ('classifier', LogisticRegression(max_iter=1000))  # Use Logistic Regression as the classifier
])

# Train the model
pipeline.fit(X_train, y_train)

# Create models directory if it doesn't exist
os.makedirs('models', exist_ok=True)

# Save the trained model
with open('models/vulnerability_classifier.pkl', 'wb') as model_file:
    pickle.dump(pipeline, model_file)

# Evaluate the model
accuracy = pipeline.score(X_test, y_test)
print(f'\nModel accuracy: {accuracy * 100:.2f}%')
